import time
import signal
import cv2
import serial
import numpy as np

# =========================
# CONFIG: Serial (Nano) + Camera
# =========================
SERIAL_PORT = "/dev/ttyUSB0"     # change if your Nano appears as /dev/ttyACM0
BAUD = 115200

CAM_INDEX = 0                   # webcam index
W, H = 1280, 720                # requested camera resolution

# =========================
# ROI: the part of the image we analyze
# (should mostly show the floor/path in front of the robot)
# =========================
ROI_X1 = int(W * 0.22)
ROI_X2 = int(W * 0.78)
ROI_Y1 = int(H * 0.58)
ROI_Y2 = int(H * 0.95)

# =========================
# BEHAVIOR TUNING: earlier + stronger avoidance
# =========================
SOFT_STOP_CM = 50.0            # start avoiding earlier than Nano HARD stop
BACKUP_S = 0.35                # reverse to create turning space
TURN_TIME_S = 0.75             # longer pivot turn (more aggressive)
FORWARD_BURST_S = 0.06         # smaller forward steps (react faster)
CLEAR_CM = 45.0                # after turn, require distance > this
TURN_ATTEMPTS = 3              # repeat turn+check a few times

# =========================
# STABILITY: avoid reacting to one noisy distance reading
# =========================
ThisManyCloseReadings = 2       # consecutive close readings needed
close_count = 0

# =========================
# VISION: floor segmentation tuning
# =========================
# The algorithm assumes bottom-center of ROI is floor and uses it as reference.
FLOOR_PATCH_W_FRAC = 0.25
FLOOR_PATCH_H_FRAC = 0.18

# Adaptive threshold settings (LAB difference)
K_STD = 3.5
MIN_THRESH = 35
MAX_THRESH = 120

# If segmentation fails badly, fallback to edge density
USE_EDGE_FALLBACK = True

# Headless mode for SSH: no imshow windows, only prints
HEADLESS = True

# =========================
# SETUP: open serial + camera
# =========================
ser = serial.Serial(SERIAL_PORT, BAUD, timeout=0.25)
time.sleep(2.0)  # Nano resets when serial opens

cap = cv2.VideoCapture(CAM_INDEX)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, W)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, H)

# SIGINT handler so Ctrl+C stops the loop cleanly
running = True
def handle_sigint(sig, frame):
    global running
    running = False
signal.signal(signal.SIGINT, handle_sigint)

# =========================
# SERIAL HELPERS
# =========================
def send_cmd(c: str):
    """Send one-letter command to Nano: F,B,L,R,S."""
    ser.write((c + "\n").encode())

_last_dist = None
_last_dist_t = 0.0

def get_distance_cm(rate_hz=10):
    """Ask Nano for distance at most rate_hz times per second."""
    global _last_dist, _last_dist_t
    now = time.time()
    if now - _last_dist_t < 1.0 / rate_hz:
        return _last_dist
    _last_dist_t = now

    ser.reset_input_buffer()
    ser.write(b'?\n')
    line = ser.readline().decode(errors='ignore').strip()

    if line.startswith("D:"):
        try:
            v = float(line[2:])
            _last_dist = None if v < 0 else v
        except:
            _last_dist = None
    else:
        _last_dist = None

    return _last_dist

# =========================
# VISION: score left vs right openness
# =========================
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))

def edge_fallback_scores(roi_bgr):
    """Fallback method: fewer edges = more open."""
    gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(gray, 60, 140)
    h, w = edges.shape
    left = edges[:, :w // 2]
    right = edges[:, w // 2:]
    return float(left.sum()), float(right.sum()), edges

def free_space_scores(frame):
    """
    Floor segmentation:
    1) Crop ROI
    2) Convert to LAB
    3) Use bottom-center patch as floor reference
    4) Pixels far from floor reference become "obstacle mask"
    5) Compare mask density left vs right
    """
    roi = frame[ROI_Y1:ROI_Y2, ROI_X1:ROI_X2]
    rh, rw = roi.shape[:2]

    # LAB makes color differences more stable than raw RGB
    lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB).astype(np.int16)

    # Floor reference patch: bottom center of ROI
    pw = int(rw * FLOOR_PATCH_W_FRAC)
    ph = int(rh * FLOOR_PATCH_H_FRAC)
    px1 = (rw - pw) // 2
    px2 = px1 + pw
    py2 = rh
    py1 = max(0, rh - ph)

    floor_patch = lab[py1:py2, px1:px2]
    floor_mean = floor_patch.reshape(-1, 3).mean(axis=0)

    # Per-pixel difference from floor mean (sum abs diff in LAB)
    diff = np.abs(lab - floor_mean).sum(axis=2).astype(np.int16)

    # Adaptive threshold based on floor patch variation
    floor_diff = diff[py1:py2, px1:px2].astype(np.float32)
    th = float(floor_diff.mean() + K_STD * floor_diff.std())
    th = max(MIN_THRESH, min(MAX_THRESH, th))

    # Obstacle mask: pixels that do NOT look like the floor
    mask = (diff > th).astype(np.uint8) * 255

    # Clean up mask (remove speckles, fill small holes)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)

    # If mask is almost all black or all white, segmentation likely failed → fallback
    occ = mask.mean() / 255.0
    if USE_EDGE_FALLBACK and (occ < 0.01 or occ > 0.95):
        eL, eR, edges = edge_fallback_scores(roi)
        return eL, eR, f"edges(th={th:.0f})"

    # Score by average mask intensity per side (0..255). Lower = clearer.
    left = mask[:, :rw // 2]
    right = mask[:, rw // 2:]
    scoreL = float(left.mean())
    scoreR = float(right.mean())
    return scoreL, scoreR, f"floor(th={th:.0f} occ={occ:.2f})"

def choose_direction(scoreL, scoreR):
    """Choose the side with lower obstacle score."""
    return 'L' if scoreL < scoreR else 'R'

# =========================
# AVOIDANCE ROUTINE
# =========================
def avoid(direction):
    """
    Stop, back up, pivot, and re-check distance.
    Repeat a few times to ensure clearance.
    """
    send_cmd('S'); time.sleep(0.05)

    send_cmd('B'); time.sleep(BACKUP_S)
    send_cmd('S'); time.sleep(0.05)

    for _ in range(TURN_ATTEMPTS):
        send_cmd(direction); time.sleep(TURN_TIME_S)
        send_cmd('S'); time.sleep(0.05)

        d2 = get_distance_cm(rate_hz=20)
        if d2 is not None and d2 > CLEAR_CM:
            return True

        send_cmd('B'); time.sleep(0.20)
        send_cmd('S'); time.sleep(0.05)

    return False

# =========================
# MAIN LOOP
# =========================
try:
    send_cmd('S')

    while running:
        ok, frame = cap.read()
        if not ok:
            send_cmd('S')
            time.sleep(0.1)
            continue

        # Read ultrasonic distance from Nano
        d = get_distance_cm(rate_hz=10)

        # Compute vision scores in ROI
        scoreL, scoreR, mode = free_space_scores(frame)
        direction = choose_direction(scoreL, scoreR)

        # Confirm closeness with multiple readings
        if d is None:
            close_count = 0
        else:
            close_count = close_count + 1 if d <= SOFT_STOP_CM else 0

        if d is None:
            send_cmd('S')
            if HEADLESS:
                print("dist=None action=STOP")
            time.sleep(0.05)

        elif close_count >= ThisManyCloseReadings:
            if HEADLESS:
                print(f"dist={d:.1f} {mode} scoreL={scoreL:.1f} scoreR={scoreR:.1f} dir={direction} action=AVOID")

            ok1 = avoid(direction)
            if not ok1:
                # If turning that way didn’t create clearance, try the other side
                other = 'L' if direction == 'R' else 'R'
                if HEADLESS:
                    print(f"not clear -> try other={other}")
                avoid(other)

            close_count = 0

        else:
            if HEADLESS:
                print(f"dist={d:.1f} {mode} scoreL={scoreL:.1f} scoreR={scoreR:.1f} dir={direction} action=FWD")
            send_cmd('F')
            time.sleep(FORWARD_BURST_S)

finally:
    # Always stop motors and clean up
    try: send_cmd('S')
    except: pass
    try: cap.release()
    except: pass
    try: cv2.destroyAllWindows()
    except: pass
    try: ser.close()
    except: pass
    print("Stopped cleanly.")
